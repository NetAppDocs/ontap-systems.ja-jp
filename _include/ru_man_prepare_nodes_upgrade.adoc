= 
:allow-uri-read: 


元のノードを交換する前に、ノードが HA ペア構成になっていて、不足しているディスクや障害ディスクがないこと、相互のストレージにアクセスできること、およびクラスタ内の他のノードに割り当てられているデータ LIF を所有していないことを確認する必要があります。また、元のノードに関する情報を収集する必要があります。クラスタが SAN 環境にある場合は、クラスタ内のすべてのノードがクォーラムにあることを確認する必要があります。

.手順
. テイクオーバーモード時に両方のノードの負荷に対応できるだけの十分なリソースが元の各ノードにあることを確認します。
+
を参照してください link:other_references.html["参考資料"] ONTAP 9 ハイアベイラビリティ構成ガイドへのリンクと、 HA ペアのベストプラクティスセクションのリンクをクリックしてください。元のノードのどちらも 50% 以上の利用率で実行しないでください。あるノードの利用率が 50% 未満の場合は、コントローラのアップグレード中に両方のノードの負荷を処理できます。

. 元のノードのパフォーマンスベースラインを作成するには、次の手順を実行します。
+
.. 診断ユーザアカウントのロックが解除されていることを確認します。
+
* 重要 * ：診断ユーザアカウントは、低レベルの診断のみを目的としており、テクニカルサポートからの指示があった場合にのみ使用してください。

+
* 重要 * ：ユーザーアカウントのロック解除については、を参照してください link:other_references.html["参考資料"] をクリックして、 _System Administration Reference_( システム管理リファレンス ) にリンクします。

.. を参照してください link:other_references.html["参考資料"] ネットアップサポートサイトへのリンクには、 Performance and Statistics Collector （ Perfstat Converged ）をダウンロードしてください。
+
Perfstat Converged ツールを使用すると、アップグレード後に比較するためのパフォーマンスのベースラインを設定できます。

.. ネットアップサポートサイトの手順に従ってパフォーマンスのベースラインを作成します。


. を参照してください link:other_references.html["参考資料"] からネットアップサポートサイトにリンクして、ネットアップサポートサイトでサポートケースをオープンしてください。
+
アップグレード中に発生する可能性がある問題をケースで報告できます。

. node3 と node4 の NVMEM または NVRAM バッテリが充電されていることを確認し、充電されていない場合は充電します。
+
node3 と node4 を物理的にチェックして、 NVMEM または NVRAM バッテリが充電されているかどうかを確認する必要があります。node3 と node4 のモデルの LED の詳細については、を参照してください link:other_references.html["参考資料"] Hardware Universe にリンクするには、次の手順を実行します。

+

WARNING: * 注意 * NVRAM の内容は消去しないでください。NVRAM の内容をクリアする必要がある場合は、ネットアップテクニカルサポートにお問い合わせください。

. node3 と node4 にある ONTAP のバージョンを確認します。
+
新しいノードには、元のノードと同じバージョンの ONTAP 9.x がインストールされている必要があります。新しいノードに別のバージョンの ONTAP がインストールされている場合は、設置後に新しいコントローラをネットブートする必要があります。ONTAP のアップグレード方法については、を参照してください link:other_references.html["参考資料"] ONTAP 9 アップグレードおよびリバート / ダウングレードガイドへのリンク。

+
node3 と node4 にある ONTAP のバージョンに関する情報は、梱包箱に含める必要があります。ONTAP のバージョンは、ノードがブートするとき、またはノードを保守モードでブートしてコマンドを実行するときに表示されます。

+
「バージョン」

. ノード 1 とノード 2 にクラスタ LIF が 2 つまたは 4 つあるかどうかを確認します。
+
「 network interface show -role cluster 」のように表示されます

+
次の例に示すように、すべてのクラスタ LIF が表示されます。

+
....
cluster::> network interface show -role cluster
        Logical    Status     Network          Current  Current Is
Vserver Interface  Admin/Oper Address/Mask     Node     Port    Home
------- ---------- ---------- ---------------- -------- ------- ----
node1
        clus1      up/up      172.17.177.2/24  node1    e0c     true
        clus2      up/up      172.17.177.6/24  node1    e0e     true
node2
        clus1      up/up      172.17.177.3/24  node2    e0c     true
        clus2      up/up      172.17.177.7/24  node2    e0e     true
....
. ノード 1 またはノード 2 にクラスタ LIF が 2 つまたは 4 つある場合は、次の手順を実行して、使用可能なすべてのパスで両方のクラスタ LIF に ping を送信できることを確認します。
+
.. advanced 権限レベルに切り替えます。
+
「 advanced 」の権限が必要です

+
次のメッセージが表示されます。

+
....
Warning: These advanced commands are potentially dangerous; use them only when directed to do so by NetApp personnel.
Do you wish to continue? (y or n):
....
.. 「 y 」と入力します。
.. ノードに ping を実行して接続をテストします。
+
cluster ping-cluster -node node_name

+
次の例のようなメッセージが表示されます。

+
....
cluster::*> cluster ping-cluster -node node1
Host is node1
Getting addresses from network interface table...
Local = 10.254.231.102 10.254.91.42
Remote = 10.254.42.25 10.254.16.228
Ping status:
...
Basic connectivity succeeds on 4 path(s) Basic connectivity fails on 0 path(s)
................
Detected 1500 byte MTU on 4 path(s):
Local 10.254.231.102 to Remote 10.254.16.228
Local 10.254.231.102 to Remote 10.254.42.25
Local 10.254.91.42 to Remote 10.254.16.228
Local 10.254.91.42 to Remote 10.254.42.25
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
....
+
ノードで 2 つのクラスタポートが使用されている場合、次の例に示すように、 4 つのパスで通信可能であることを確認できます。

.. 管理者レベルの権限に戻ります。
+
「特権管理者」



. ノード 1 とノード 2 が HA ペアになっていることを確認し、ノードが相互に接続されていること、およびテイクオーバーが可能であることを確認します。
+
「 storage failover show 」をクリックします

+
次の例は、ノードが相互に接続されていて、テイクオーバーが可能な場合の出力例を示しています。

+
....
cluster::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------
node1          node2          true     Connected to node2
node2          node1          true     Connected to node1
....
+
どちらのノードも部分的なギブバック状態にはなりません。次の例では、 node1 の部分的なギブバックが完了しています。

+
....
cluster::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------
node1          node2          true     Connected to node2, Partial giveback
node2          node1          true     Connected to node1
....
+
いずれかのノードが部分的なギブバック状態にある場合は、「 storage failover giveback 」コマンドを使用してギブバックを実行し、「 storage failover show-giveback 」コマンドを使用して、ギブバックする必要がないことを確認します。コマンドの詳細については、を参照してください link:other_references.html["参考資料"] ONTAP 9 ハイアベイラビリティ構成ガイドへのリンク。

. [man_prepare-to-downgrade 9] ： node1 と node2 のどちらも現在の所有者（ホーム所有者ではない）のアグリゲートを所有していないことを確認します。
+
「 storage aggregate show -node <node_name > -is-home false -fields owner-name 、 homename 、 state 」という文字列が含まれています

+
node1 と node2 のどちらも現在の所有者（ホーム所有者ではない）アグリゲートを所有していない場合、次の例のようなメッセージが返されます。

+
....
cluster::> storage aggregate show -node node2 -is-home false -fields owner-name,homename,state
There are no entries matching your query.
....
+
次の例は、 4 つのアグリゲートのホーム所有者ではなくホーム所有者である node2 というノードに対するコマンドの出力を示しています。

+
....
cluster::> storage aggregate show -node node2 -is-home false
               -fields owner-name,home-name,state

aggregate     home-name    owner-name   state
------------- ------------ ------------ ------
aggr1         node1        node2        online
aggr2         node1        node2        online
aggr3         node1        node2        online
aggr4         node1        node2        online

4 entries were displayed.
....
. 次のいずれかを実行します。
+
[cols="35,65"]
|===
| のコマンドの場合は <<man_prepare_nodes_step9,手順 9>>... | 作業 


| 空の出力がありました | 手順 11 を省略して、に進みます <<man_prepare_nodes_step12,手順 12>>。 


| 出力あり | に進みます <<man_prepare_nodes_step11,手順 11>>。 
|===
. [man_prepare-to-downgrade 11]] ノード 1 またはノード 2 が現在の所有者であり、ホーム所有者ではないアグリゲートを所有している場合は、次の手順を実行します。
+
.. パートナーノードが現在所有しているアグリゲートをホーム所有者ノードに戻します。
+
「 storage failover giveback -ofnode <home_node_name >`

.. node1 と node2 のどちらも現在の所有者（ホーム所有者ではない）アグリゲートを所有していないことを確認します。
+
「 storage aggregate show -nodes <node_name > -is-home false -fields owner-name 、 home-name 、 state

+
次の例は、アグリゲートの現在の所有者とホーム所有者の両方がノードにある場合のコマンドの出力例を示しています。

+
....
cluster::> storage aggregate show -nodes node1
          -is-home true -fields owner-name,home-name,state

aggregate     home-name    owner-name   state
------------- ------------ ------------ ------
aggr1         node1        node1        online
aggr2         node1        node1        online
aggr3         node1        node1        online
aggr4         node1        node1        online

4 entries were displayed.
....


. [man_prepare_nodes_step12]] ノード 1 とノード 2 がお互いのストレージにアクセスできることを確認し、ディスクが見つからないことを確認します。
+
「 storage failover show -fields local-missing-disks 、 partner-missing-disks 」というメッセージが表示されます

+
次の例は、不足しているディスクがない場合の出力例を示しています。

+
....
cluster::> storage failover show -fields local-missing-disks,partner-missing-disks

node     local-missing-disks partner-missing-disks
-------- ------------------- ---------------------
node1    None                None
node2    None                None
....
+
足りないディスクがある場合は、を参照してください link:other_references.html["参考資料"] ONTAP 9 ディスクとアグリゲートパワーガイドへのリンク、 ONTAP 9 論理ストレージ管理ガイド _ 、および ONTAP 9 ハイアベイラビリティ構成ガイド _ にリンクして、 HA ペアのストレージを設定します。

. ノード 1 とノード 2 が正常に機能しており、クラスタへの参加条件を満たしていることを確認します。
+
「 cluster show 」を参照してください

+
次の例は、両方のノードが正常である場合の出力を示しています。

+
....
cluster::> cluster show

Node                  Health  Eligibility
--------------------- ------- ------------
node1                 true    true
node2                 true    true
....
. 権限レベルを advanced に設定します。
+
「 advanced 」の権限が必要です

. [man_prepare-to-downgrade 15]] ノード 1 とノード 2 で同じ ONTAP リリースが実行されていることを確認します。
+
「 system node image show -node <node1 、 node2 > -iscurrent true 」

+
次の例は、コマンドの出力例を示しています。

+
....
cluster::*> system node image show -node node1,node2 -iscurrent true

                 Is      Is                Install
Node     Image   Default Current Version   Date
-------- ------- ------- ------- --------- -------------------
node1
         image1  true    true    9.1         2/7/2017 20:22:06
node2
         image1  true    true    9.1         2/7/2017 20:20:48

2 entries were displayed.
....
. ノード 1 とノード 2 のどちらもクラスタ内の他のノードに属するデータ LIF を所有していないことを確認し、出力の「 Current Node 」列と「 Is Home 」列をチェックします。
+
network interface show -role data -is-home false -curr-node <node_name >`

+
次の例は、 node1 に、ホーム所有の LIF がクラスタ内の他のノードにない場合の出力を示しています。

+
....
cluster::> network interface show -role data -is-home false -curr-node node1
 There are no entries matching your query.
....
+
次の例は、 node1 がもう一方のノードによってホーム所有されているデータ LIF を所有している場合の出力を示しています。

+
....
cluster::> network interface show -role data -is-home false -curr-node node1

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
vs0
            data1      up/up      172.18.103.137/24  node1         e0d     false
            data2      up/up      172.18.103.143/24  node1         e0f     false

2 entries were displayed.
....
. の出力の場合は <<man_prepare_nodes_step15,手順 15>> ノード 1 とノード 2 のどちらかがクラスタ内の他のノードでホーム所有されているデータ LIF を所有しており、データ LIF をノード 1 とノード 2 のどちらからも移行することを示します。
+
network interface revert -vserver * -lif *

+
network interface revert コマンドの詳細については、を参照してください link:other_references.html["参考資料"] ONTAP 9 コマンド：マニュアルページリファレンスにリンクするには、次の手順を実行します。

. ノード 1 とノード 2 で障害ディスクが所有されているかどうかを確認します。
+
'storage disk show -nodelist <node1 、 node2 > -boled

+
いずれかのディスクで障害が発生した場合は、 ONTAP 9 ディスクとアグリゲートパワーガイドの手順に従ってディスクを取り外します。を参照してください link:other_references.html["参考資料"] ONTAP 9 ディスクとアグリゲートパワーガイドにリンクするには、を参照してください）。

. 次の手順を実行して node1 と node2 に関する情報を収集し、各コマンドの出力を記録します。
+

NOTE: この情報は、手順の後半で使用します。

+
.. 両方のノードのモデル、システム ID 、シリアル番号を記録します。
+
「 system node show -node <node1 、 node2 > -instance 」のように表示されます

+

NOTE: この情報を使用して、ディスクの再割り当てと元のノードの運用を停止します。

.. ノード 1 とノード 2 の両方で次のコマンドを入力し、シェルフ、各シェルフ内のディスク数、フラッシュストレージの詳細、メモリ、 NVRAM 、ネットワークカードに関する情報を出力に記録します。
+
'run-node <node_name >sysconfig `

+

NOTE: この情報を使用して、 node3 または node4 に転送するパーツやアクセサリを特定できます。ノードが V シリーズシステムであるか、 FlexArray 仮想化ソフトウェアがインストールされているかがわからない場合は、の出力からも確認できます。

.. ノード 1 とノード 2 の両方で次のコマンドを入力し、両方のノードでオンラインになっているアグリゲートを記録します。
+
「 storage aggregate show -node <node_name > -state online 」のように指定します

+

NOTE: この情報と次の手順の情報を使用して、再配置時にオフラインになった短時間のアグリゲートとボリュームが手順全体でオンラインのままになっていることを確認できます。

.. [[man_prepare_nodes_step19]] ノード 1 とノード 2 の両方で次のコマンドを入力し、両方のノードでオフラインになっているボリュームを記録します。
+
volume show -node <node_name > -state offline`

+

NOTE: アップグレード後にもう一度コマンドを実行し、この手順の出力と比較して、他のボリュームがオフラインになったかどうかを確認します。



. 次のコマンドを入力して、 node1 または node2 にインターフェイスグループまたは VLAN が設定されているかどうかを確認します。
+
「 network port ifgrp show 」のように表示されます

+
「 network port vlan show 」と表示されます

+
インターフェイスグループまたは VLAN がノード 1 とノード 2 のどちらで設定されているかを確認します。手順の次の手順以降で、その情報を確認する必要があります。

. ノード 1 とノード 2 の両方で次の手順を実行して、手順の後半で物理ポートを正しくマッピングできることを確認します。
+
.. 次のコマンドを入力して 'clusterwide 以外のノードにフェイルオーバー・グループがあるかどうかを確認します
+
「 network interface failover-groups show 」と表示されます

+
フェイルオーバーグループは、システムに存在するネットワークポートのセットです。コントローラハードウェアをアップグレードすると物理ポートの場所が変わる可能性があるため、アップグレード中にフェイルオーバーグループを誤って変更する可能性があります。

+
次の例に示すように、ノード上のフェイルオーバーグループが表示されます。

+
....
cluster::> network interface failover-groups show

Vserver             Group             Targets
------------------- ----------------- ----------
Cluster             Cluster           node1:e0a, node1:e0b
                                      node2:e0a, node2:e0b

fg_6210_e0c         Default           node1:e0c, node1:e0d
                                      node1:e0e, node2:e0c
                                      node2:e0d, node2:e0e

2 entries were displayed.
....
.. clusterwide 以外のフェイルオーバー・グループがある場合は ' フェイルオーバー・グループ名と ' そのフェイルオーバー・グループに属するポートを記録します
.. 次のコマンドを入力して、ノードに VLAN が設定されているかどうかを確認します。
+
「 network port vlan show -node <node_name >` 」のように指定します

+
VLAN は物理ポートを介して設定されます。物理ポートが変わった場合は、あとで手順で VLAN を再作成する必要があります。

+
次の例に示すように、ノードに設定されている VLAN が表示されます。

+
....
cluster::> network port vlan show

Network Network
Node    VLAN Name Port    VLAN ID MAC Address
------  --------- ------- ------- ------------------
node1   e1b-70    e1b     70      00:15:17:76:7b:69
....
.. ノードに VLAN が設定されている場合は、各ネットワークポートと VLAN ID のペアをメモします。


. 次のいずれかを実行します。
+
[cols="35,65"]
|===
| インターフェイスグループまたは VLAN の状態 | 作業 


| ノード 1 またはノード 2 | - 完了しました <<man_prepare_nodes_step23,手順 23>> および <<man_prepare_nodes_step24,手順 24>>。 


| ノード 1 とノード 2 ではありません | に進みます <<man_prepare_nodes_step24,手順 24>>。 
|===
. [[man_prepare_nodes_step23]] SAN 環境または SAN 以外の環境で node1 と node2 が存在するかどうかが不明な場合は、次のコマンドを入力して出力を確認します。
+
network interface show -vserver <vserver_name> -data-protocol iscsi|fcp`

+
SVM に iSCSI も FC も設定されていない場合、次の例のようなメッセージが表示されます。

+
....
cluster::> network interface show -vserver Vserver8970 -data-protocol iscsi|fcp
There are no entries matching your query.
....
+
ノードが NAS 環境にあることを確認するには '-data-protocol nfs|cifs パラメータを指定した network interface show コマンドを使用します

+
SVM に iSCSI または FC が設定されている場合、次の例のようなメッセージが表示されます。

+
....
cluster::> network interface show -vserver vs1 -data-protocol iscsi|fcp

         Logical    Status     Network            Current  Current Is
Vserver  Interface  Admin/Oper Address/Mask       Node     Port    Home
-------- ---------- ---------- ------------------ -------- ------- ----
vs1      vs1_lif1   up/down    172.17.176.20/24   node1    0d      true
....
. [man_prepare-to-downgrade 24]] 次の手順を実行して、クラスタ内のすべてのノードがクォーラムにあることを確認します。
+
.. advanced 権限レベルに切り替えます。
+
「 advanced 」の権限が必要です

+
次のメッセージが表示されます。

+
....
Warning: These advanced commands are potentially dangerous; use them only when directed to do so by NetApp personnel.
Do you wish to continue? (y or n):
....
.. 「 y 」と入力します。
.. カーネル内のクラスタサービスの状態をノードごとに 1 回確認します。
+
「 cluster kernel-service show 」のように表示されます

+
次の例のようなメッセージが表示されます。

+
....
cluster::*> cluster kernel-service show

Master        Cluster       Quorum        Availability  Operational
Node          Node          Status        Status        Status
------------- ------------- ------------- ------------- -------------
node1         node1         in-quorum     true          operational
              node2         in-quorum     true          operational

2 entries were displayed.
....
+
過半数のノードが正常で相互に通信可能な場合に、クラスタ内のノードがクォーラムを構成している。詳細については、を参照してください link:other_references.html["参考資料"] をクリックして、 _System Administration Reference_( システム管理リファレンス ) にリンクします。

.. admin 権限レベルに戻ります。
+
「特権管理者」



. 次のいずれかを実行します。
+
[cols="35,65"]
|===
| クラスタの状況 | 作業 


| SAN が設定されている | に進みます <<man_prepare_nodes_step26,手順 26>>。 


| SAN が設定されていません | に進みます <<man_prepare_nodes_step29,手順 29>>。 
|===
. [man_prepare-to-downgrade 26]] 次のコマンドを入力して、 SAN iSCSI または FC サービスが有効になっている各 SVM で、ノード 1 とノード 2 に SAN LIF があることを確認します。
+
'network interface show -data-protocol iscsi|fcp-home-node <node_name >`

+
コマンドは、ノード 1 とノード 2 の SAN LIF 情報を表示します。次の例は、 Status Admin/Oper 列に up/up と表示されているステータスを示しています。これは、 SAN iSCSI サービスと FC サービスが有効になっていることを示しています。

+
....
cluster::> network interface show -data-protocol iscsi|fcp
            Logical    Status     Network                  Current   Current Is
Vserver     Interface  Admin/Oper Address/Mask             Node      Port    Home
----------- ---------- ---------- ------------------       --------- ------- ----
a_vs_iscsi  data1      up/up      10.228.32.190/21         node1     e0a     true
            data2      up/up      10.228.32.192/21         node2     e0a     true

b_vs_fcp    data1      up/up      20:09:00:a0:98:19:9f:b0  node1     0c      true
            data2      up/up      20:0a:00:a0:98:19:9f:b0  node2     0c      true

c_vs_iscsi_fcp data1   up/up      20:0d:00:a0:98:19:9f:b0  node2     0c      true
            data2      up/up      20:0e:00:a0:98:19:9f:b0  node2     0c      true
            data3      up/up      10.228.34.190/21         node2     e0b     true
            data4      up/up      10.228.34.192/21         node2     e0b     true
....
+
また、次のコマンドを入力して、 LIF の詳細情報を確認することもできます。

+
'network interface show -instance -data-protocol iscsi|fcp

. 次のコマンドを入力してシステムの出力を記録し、元のノードの FC ポートのデフォルト設定を取得します。
+
ucadmin show

+
コマンドは、次の例に示すように、クラスタ内のすべての FC ポートに関する情報を表示します。

+
....
cluster::> ucadmin show

                Current Current   Pending Pending   Admin
Node    Adapter Mode    Type      Mode    Type      Status
------- ------- ------- --------- ------- --------- -----------
node1   0a      fc      initiator -       -         online
node1   0b      fc      initiator -       -         online
node1   0c      fc      initiator -       -         online
node1   0d      fc      initiator -       -         online
node2   0a      fc      initiator -       -         online
node2   0b      fc      initiator -       -         online
node2   0c      fc      initiator -       -         online
node2   0d      fc      initiator -       -         online
8 entries were displayed.
....
+
アップグレード後の情報を使用して、新しいノードに FC ポートを設定できます。

. V シリーズシステムまたは FlexArray 仮想化ソフトウェアがインストールされたシステムをアップグレードする場合は、次のコマンドを入力して出力を記録し、元のノードのトポロジに関する情報を取得します。
+
「 storage array config show -switch 」です

+
次の例に示すようにトポロジ情報が表示されます。

+
....
cluster::> storage array config show -switch

      LUN LUN                                  Target Side Initiator Side Initi-
Node  Grp Cnt Array Name    Array Target Port  Switch Port Switch Port    ator
----- --- --- ------------- ------------------ ----------- -------------- ------
node1 0   50  I_1818FAStT_1
                            205700a0b84772da   vgbr6510a:5  vgbr6510s164:3  0d
                            206700a0b84772da   vgbr6510a:6  vgbr6510s164:4  2b
                            207600a0b84772da   vgbr6510b:6  vgbr6510s163:1  0c
node2 0   50  I_1818FAStT_1
                            205700a0b84772da   vgbr6510a:5  vgbr6510s164:1  0d
                            206700a0b84772da   vgbr6510a:6  vgbr6510s164:2  2b
                            207600a0b84772da   vgbr6510b:6  vgbr6510s163:3  0c
                            208600a0b84772da   vgbr6510b:5  vgbr6510s163:4  2a
7 entries were displayed.
....
. [man_prepare-to-downgrade 29]] 次の手順を実行します。
+
.. 元のいずれかのノードで次のコマンドを入力し、出力を記録します。
+
「 service-processor show -node * -instance 」のように表示されます

+
両方のノードの SP に関する詳細情報が表示されます。

.. SP のステータスが「オンライン」であることを確認します。
.. SP ネットワークが設定されていることを確認します。
.. SP の IP アドレスやその他の情報を記録します。


+
リモート管理デバイスのネットワーク・パラメータ（この場合は SP ）を ' 新しいノードの SP の元のシステムから再利用することができますSP の詳細については ' を参照してください link:other_references.html["参考資料"] 『 _System Administration Reference_and the ONTAP 9 Commands ： Manual Page Reference_』 にリンクするには、次の手順を実行します。

. [man_prepare-to-downgrade 30]] 新しいノードに元のノードと同じライセンス機能を設定する場合は、次のコマンドを入力して元のシステムのクラスタライセンスを表示します。
+
「 system license show -owner * 」と表示されます

+
次の例では、 cluster1 のサイトライセンスを表示しています。

+
....
system license show -owner *
Serial Number: 1-80-000013
Owner: cluster1

Package           Type    Description           Expiration
----------------- ------- --------------------- -----------
Base              site    Cluster Base License  -
NFS               site    NFS License           -
CIFS              site    CIFS License          -
SnapMirror        site    SnapMirror License    -
FlexClone         site    FlexClone License     -
SnapVault         site    SnapVault License     -
6 entries were displayed.
....
. 新しいノードの新しいライセンスキーを the _NetApp Support Site_. に取得します。を参照してください link:other_references.html["参考資料"] からネットアップサポートサイトにリンクしてください。
+
必要なライセンスキーがサイトにない場合は、ネットアップの営業担当者にお問い合わせください。

. 元のシステムで AutoSupport が有効になっているかどうかを確認するには、各ノードで次のコマンドを入力し、出力を調べます。
+
「 system node AutoSupport show -node <node1 、 node2 > 」のように表示されます

+
次の例に示すように、コマンド出力には AutoSupport が有効になっているかどうかが表示されます。

+
....
cluster::> system node autosupport show -node node1,node2

Node             State     From          To                Mail Hosts
---------------- --------- ------------- ----------------  ----------
node1            enable    Postmaster    admin@netapp.com  mailhost

node2            enable    Postmaster    -                 mailhost
2 entries were displayed.
....
. 次のいずれかを実行します。
+
[cols="35,65"]
|===
| 元のシステム | 作業 


| AutoSupport が有効になっています ...  a| 
.. に進みます <<man_prepare_nodes_step34,手順 34>>。
.. セクションに移動します link:get_address_key_management_server_encryption.html["ストレージ暗号化用の外部キー管理サーバの IP アドレスを取得します"]。




| AutoSupport が有効になっていません ...  a| 
.. AutoSupport を有効にするには、 _System Administration Reference_. の手順に従ってください。を参照してください link:other_references.html["参考資料"] をクリックして、 _System Administration Reference_. にリンクします。）
+
* 注： AutoSupport は、ストレージ・システムを初めて設定したときに、デフォルトで有効になっています。AutoSupport はいつでも無効にできますが、常に有効にしておく必要があります。AutoSupport を有効にすると、ストレージシステムに問題が発生したときに、その問題や解決策を特定するのに非常に役立ちます。

.. にアクセスします link:get_address_key_management_server_encryption.html["ストレージ暗号化用の外部キー管理サーバの IP アドレスを取得します"] セクション。


|===
. [man_prepare_nodes _step34]] 元のノードの両方で次のコマンドを入力し、 AutoSupport が正しいメールホストの詳細および受信者の E メール ID で設定されていることを確認します。
+
「 system node AutoSupport show -node node_name -instance 」の略

+
AutoSupport の詳細については、を参照してください link:other_references.html["参考資料"] 『 _System Administration Reference_and the ONTAP 9 Commands ： Manual Page Reference_』 にリンクするには、次の手順を実行します。

. [[man_prepare-to-downgrade 35 、 Step 35]] 次のコマンドを入力して、 node1 のネットアップに AutoSupport メッセージを送信します。
+
「 system node AutoSupport invoke -node node1 -type all -message 」「 Upgrading node1 from platform_old to platform_new 」というメッセージが表示されます

+

NOTE: この時点では node2 の AutoSupport メッセージはネットアップに送信しないでください。これはあとで手順で送信します。

. [man_prepare-to-downgrade 36 、 Step 36]] 次のコマンドを入力して、 AutoSupport メッセージが送信されたことを確認します。
+
「 system node AutoSupport show -node <node1> -instance 」のように表示されます

+
「 Last Subject Sent ：」フィールドと「 Last Time Sent ：」フィールドには、最後に送信されたメッセージのメッセージタイトルと、メッセージが送信された時刻が含まれています。


